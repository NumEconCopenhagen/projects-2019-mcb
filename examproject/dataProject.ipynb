{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the world of financial analysis, many different instruments and methods are used to determine whether or not a stock is worth investing in, and which ones to include in your portfolio. The S&P500 index is one of the biggest indexes to invest in and has, as the name indicates, over 500 stocks to analyse. The purpose of this project is to collect data for each stock listed on the S&P500 index and look at the adjusted close prices for the companies with data available from 2016 till may 20th of this year. We will collect the data through the Yahoo Finance API and compile all these into a single dataframe for us to analyse. We will use the adjusted close prices to calculate the stock returns of each stock, as well as indexing each of them by their first observation to better compare the evolution of two different stocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "write this in the Terminal:\n",
    "conda install -c anaconda pandas-datareader\n",
    "\n",
    "When asked:\n",
    "The following packages will be SUPERSEDED by a higher-priority channel:\n",
    "\n",
    "  ca-certificates                                 pkgs/main --> anaconda\n",
    "  certifi                                         pkgs/main --> anaconda\n",
    "  openssl                                         pkgs/main --> anaconda\n",
    "  qt                                              pkgs/main --> anaconda\n",
    "Proceed ([y]/n)?\n",
    "\n",
    "Press y\n",
    "\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "import requests\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import norm # normal distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to get the tickers for each of the companites on the S&P500 index list, which we later on will\n",
    "use to append all the historic data to the appropriate ticker. We use *requests.get* to access the data from Wikipedia, which is the list of tickers, after which we use *BeautifulSoup* to then read the HTML format of the website, and make a table. The *soup.find* command is used to specify where exactly in the HTML the table we want is located. \n",
    "\n",
    "We make an empty list, and use a for loop to read all entries in the column of the tickers and append each of these to the list we made (called tickers). \n",
    "\n",
    "We save it as a pickle as we want to access this data later on, and fast. We called this *\"sp500tickers.pickle\"*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM', 'ABT', 'ABBV', 'ABMD', 'ACN', 'ATVI', 'ADBE', 'AMD', 'AAP', 'AES', 'AMG', 'AFL', 'A', 'APD', 'AKAM', 'ALK', 'ALB', 'ARE', 'ALXN', 'ALGN', 'ALLE', 'AGN', 'ADS', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'ABC', 'AME', 'AMGN', 'APH', 'APC', 'ADI', 'ANSS', 'ANTM', 'AON', 'AOS', 'APA', 'AIV', 'AAPL', 'AMAT', 'APTV', 'ADM', 'ARNC', 'ANET', 'AJG', 'AIZ', 'ATO', 'T', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'BHGE', 'BLL', 'BAC', 'BK', 'BAX', 'BBT', 'BDX', 'BRK-B', 'BBY', 'BIIB', 'BLK', 'HRB', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BMY', 'AVGO', 'BR', 'BF-B', 'CHRW', 'COG', 'CDNS', 'CPB', 'COF', 'CPRI', 'CAH', 'KMX', 'CCL', 'CAT', 'CBOE', 'CBRE', 'CBS', 'CE', 'CELG', 'CNC', 'CNP', 'CTL', 'CERN', 'CF', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'XEC', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CTXS', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'CXO', 'COP', 'ED', 'STZ', 'COO', 'CPRT', 'GLW', 'COST', 'COTY', 'CCI', 'CSX', 'CMI', 'CVS', 'DHI', 'DHR', 'DRI', 'DVA', 'DE', 'DAL', 'XRAY', 'DVN', 'FANG', 'DLR', 'DFS', 'DISCA', 'DISCK', 'DISH', 'DG', 'DLTR', 'D', 'DOV', 'DOW', 'DWDP', 'DTE', 'DRE', 'DUK', 'DXC', 'ETFC', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'EMR', 'ETR', 'EOG', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'EVRG', 'ES', 'RE', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FB', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FE', 'FRC', 'FISV', 'FLT', 'FLIR', 'FLS', 'FLR', 'FMC', 'FL', 'F', 'FTNT', 'FTV', 'FBHS', 'FOXA', 'FOX', 'BEN', 'FCX', 'GPS', 'GRMN', 'IT', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GS', 'GWW', 'HAL', 'HBI', 'HOG', 'HRS', 'HIG', 'HAS', 'HCA', 'HCP', 'HP', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HFC', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HPQ', 'HUM', 'HBAN', 'HII', 'IDXX', 'INFO', 'ITW', 'ILMN', 'IR', 'INTC', 'ICE', 'IBM', 'INCY', 'IP', 'IPG', 'IFF', 'INTU', 'ISRG', 'IVZ', 'IPGP', 'IQV', 'IRM', 'JKHY', 'JEC', 'JBHT', 'JEF', 'SJM', 'JNJ', 'JCI', 'JPM', 'JNPR', 'KSU', 'K', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KSS', 'KHC', 'KR', 'LB', 'LLL', 'LH', 'LRCX', 'LW', 'LEG', 'LEN', 'LLY', 'LNC', 'LIN', 'LKQ', 'LMT', 'L', 'LOW', 'LYB', 'MTB', 'MAC', 'M', 'MRO', 'MPC', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MAT', 'MKC', 'MXIM', 'MCD', 'MCK', 'MDT', 'MRK', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MHK', 'TAP', 'MDLZ', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'MYL', 'NDAQ', 'NOV', 'NKTR', 'NTAP', 'NFLX', 'NWL', 'NEM', 'NWSA', 'NWS', 'NEE', 'NLSN', 'NKE', 'NI', 'NBL', 'JWN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'ORLY', 'OXY', 'OMC', 'OKE', 'ORCL', 'PCAR', 'PKG', 'PH', 'PAYX', 'PYPL', 'PNR', 'PBCT', 'PEP', 'PKI', 'PRGO', 'PFE', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PSA', 'PHM', 'PVH', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTN', 'O', 'RHT', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'CRM', 'SBAC', 'SLB', 'STX', 'SEE', 'SRE', 'SHW', 'SPG', 'SWKS', 'SLG', 'SNA', 'SO', 'LUV', 'SPGI', 'SWK', 'SBUX', 'STT', 'SYK', 'STI', 'SIVB', 'SYMC', 'SYF', 'SNPS', 'SYY', 'TROW', 'TTWO', 'TPR', 'TGT', 'TEL', 'FTI', 'TFX', 'TXN', 'TXT', 'TMO', 'TIF', 'TWTR', 'TJX', 'TMK', 'TSS', 'TSCO', 'TDG', 'TRV', 'TRIP', 'TSN', 'UDR', 'ULTA', 'USB', 'UAA', 'UA', 'UNP', 'UAL', 'UNH', 'UPS', 'URI', 'UTX', 'UHS', 'UNM', 'VFC', 'VLO', 'VAR', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VIAB', 'V', 'VNO', 'VMC', 'WAB', 'WMT', 'WBA', 'DIS', 'WM', 'WAT', 'WEC', 'WCG', 'WFC', 'WELL', 'WDC', 'WU', 'WRK', 'WY', 'WHR', 'WMB', 'WLTW', 'WYNN', 'XEL', 'XRX', 'XLNX', 'XYL', 'YUM', 'ZBH', 'ZION', 'ZTS']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABMD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker\n",
       "0    MMM\n",
       "1    ABT\n",
       "2   ABBV\n",
       "3   ABMD\n",
       "4    ACN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Automating S&P500 - From Yahoo Finance - Close price adjusted for splits, and Adj. Close price is adjusted for both dividends and splits.\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "    soup = bs.BeautifulSoup(resp.text, \"lxml\")\n",
    "    table = soup.find(\"table\", {\"class\": \"wikitable sortable\"})\n",
    "    tickers = []\n",
    "    for row in table.findAll(\"tr\")[1:]:\n",
    "        ticker = row.findAll(\"td\")[0].text.replace(\".\",\"-\")\n",
    "        ticker = ticker[:-1]\n",
    "        tickers.append(ticker)\n",
    "\n",
    "    df_tickers = pd.DataFrame(tickers)\n",
    "    df_tickers.to_csv(\"tickers.csv\")\n",
    "\n",
    "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
    "        pickle.dump(tickers, f)\n",
    "    \n",
    "        print(tickers)\n",
    "\n",
    "        return(tickers)\n",
    "    \n",
    "save_sp500_tickers()\n",
    "\n",
    "df_tickers = pd.read_csv(\"tickers.csv\", index_col= 0)\n",
    "df_tickers.columns = [\"Ticker\"]\n",
    "df_tickers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need data for each ticker we have in the list. We get this from yahoo, and using the *DataReader* from pandas. \n",
    "\n",
    "Remember we saved the tickers as a pickle file, which we will now open and use to append the data to. Also, we make a separate folder for all of the CSV files we will get. We suggest you download the stocks_dfs folder from our repository, as this should save some time. Otherwise you can run the code and a folder with all stock data will be created for you. We define appropriate start and end dates for the data we want, which in this case has been chosen to be the start of 2016 and the latest date with available data. \n",
    "\n",
    "We then create a for loop, and save each CSV file with price data in the stock_dfs folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have MMM\n",
      "Already have ABT\n",
      "Already have ABBV\n",
      "Already have ABMD\n",
      "Already have ACN\n",
      "Already have ATVI\n",
      "Already have ADBE\n",
      "Already have AMD\n",
      "Already have AAP\n",
      "Already have AES\n",
      "Already have AMG\n",
      "Already have AFL\n",
      "Already have A\n",
      "Already have APD\n",
      "Already have AKAM\n",
      "Already have ALK\n",
      "Already have ALB\n",
      "Already have ARE\n",
      "Already have ALXN\n",
      "Already have ALGN\n",
      "Already have ALLE\n",
      "Already have AGN\n",
      "Already have ADS\n",
      "Already have LNT\n",
      "Already have ALL\n",
      "Already have GOOGL\n",
      "Already have GOOG\n",
      "Already have MO\n",
      "Already have AMZN\n",
      "Already have AEE\n",
      "Already have AAL\n",
      "Already have AEP\n",
      "Already have AXP\n",
      "Already have AIG\n",
      "Already have AMT\n",
      "Already have AWK\n",
      "Already have AMP\n",
      "Already have ABC\n",
      "Already have AME\n",
      "Already have AMGN\n",
      "Already have APH\n",
      "Already have APC\n",
      "Already have ADI\n",
      "Already have ANSS\n",
      "Already have ANTM\n",
      "Already have AON\n",
      "Already have AOS\n",
      "Already have APA\n",
      "Already have AIV\n",
      "Already have AAPL\n",
      "Already have AMAT\n",
      "Already have APTV\n",
      "Already have ADM\n",
      "Already have ARNC\n",
      "Already have ANET\n",
      "Already have AJG\n",
      "Already have AIZ\n",
      "Already have ATO\n",
      "Already have T\n",
      "Already have ADSK\n",
      "Already have ADP\n",
      "Already have AZO\n",
      "Already have AVB\n",
      "Already have AVY\n",
      "Already have BHGE\n",
      "Already have BLL\n",
      "Already have BAC\n",
      "Already have BK\n",
      "Already have BAX\n",
      "Already have BBT\n",
      "Already have BDX\n",
      "Already have BRK-B\n",
      "Already have BBY\n",
      "Already have BIIB\n",
      "Already have BLK\n",
      "Already have HRB\n",
      "Already have BA\n",
      "Already have BKNG\n",
      "Already have BWA\n",
      "Already have BXP\n",
      "Already have BSX\n",
      "Already have BMY\n",
      "Already have AVGO\n",
      "Already have BR\n",
      "Already have BF-B\n",
      "Already have CHRW\n",
      "Already have COG\n",
      "Already have CDNS\n",
      "Already have CPB\n",
      "Already have COF\n",
      "Already have CPRI\n",
      "Already have CAH\n",
      "Already have KMX\n",
      "Already have CCL\n",
      "Already have CAT\n",
      "Already have CBOE\n",
      "Already have CBRE\n",
      "Already have CBS\n",
      "Already have CE\n",
      "Already have CELG\n",
      "Already have CNC\n",
      "Already have CNP\n",
      "Already have CTL\n",
      "Already have CERN\n",
      "Already have CF\n",
      "Already have SCHW\n",
      "Already have CHTR\n",
      "Already have CVX\n",
      "Already have CMG\n",
      "Already have CB\n",
      "Already have CHD\n",
      "Already have CI\n",
      "Already have XEC\n",
      "Already have CINF\n",
      "Already have CTAS\n",
      "Already have CSCO\n",
      "Already have C\n",
      "Already have CFG\n",
      "Already have CTXS\n",
      "Already have CLX\n",
      "Already have CME\n",
      "Already have CMS\n",
      "Already have KO\n",
      "Already have CTSH\n",
      "Already have CL\n",
      "Already have CMCSA\n",
      "Already have CMA\n",
      "Already have CAG\n",
      "Already have CXO\n",
      "Already have COP\n",
      "Already have ED\n",
      "Already have STZ\n",
      "Already have COO\n",
      "Already have CPRT\n",
      "Already have GLW\n",
      "Already have COST\n",
      "Already have COTY\n",
      "Already have CCI\n",
      "Already have CSX\n",
      "Already have CMI\n",
      "Already have CVS\n",
      "Already have DHI\n",
      "Already have DHR\n",
      "Already have DRI\n",
      "Already have DVA\n",
      "Already have DE\n",
      "Already have DAL\n",
      "Already have XRAY\n",
      "Already have DVN\n",
      "Already have FANG\n",
      "Already have DLR\n",
      "Already have DFS\n",
      "Already have DISCA\n",
      "Already have DISCK\n",
      "Already have DISH\n",
      "Already have DG\n",
      "Already have DLTR\n",
      "Already have D\n",
      "Already have DOV\n",
      "Already have DOW\n",
      "Already have DWDP\n",
      "Already have DTE\n",
      "Already have DRE\n",
      "Already have DUK\n",
      "Already have DXC\n",
      "Already have ETFC\n",
      "Already have EMN\n",
      "Already have ETN\n",
      "Already have EBAY\n",
      "Already have ECL\n",
      "Already have EIX\n",
      "Already have EW\n",
      "Already have EA\n",
      "Already have EMR\n",
      "Already have ETR\n",
      "Already have EOG\n",
      "Already have EFX\n",
      "Already have EQIX\n",
      "Already have EQR\n",
      "Already have ESS\n",
      "Already have EL\n",
      "Already have EVRG\n",
      "Already have ES\n",
      "Already have RE\n",
      "Already have EXC\n",
      "Already have EXPE\n",
      "Already have EXPD\n",
      "Already have EXR\n",
      "Already have XOM\n",
      "Already have FFIV\n",
      "Already have FB\n",
      "Already have FAST\n",
      "Already have FRT\n",
      "Already have FDX\n",
      "Already have FIS\n",
      "Already have FITB\n",
      "Already have FE\n",
      "Already have FRC\n",
      "Already have FISV\n",
      "Already have FLT\n",
      "Already have FLIR\n",
      "Already have FLS\n",
      "Already have FLR\n",
      "Already have FMC\n",
      "Already have FL\n",
      "Already have F\n",
      "Already have FTNT\n",
      "Already have FTV\n",
      "Already have FBHS\n",
      "Already have FOXA\n",
      "Already have FOX\n",
      "Already have BEN\n",
      "Already have FCX\n",
      "Already have GPS\n",
      "Already have GRMN\n",
      "Already have IT\n",
      "Already have GD\n",
      "Already have GE\n",
      "Already have GIS\n",
      "Already have GM\n",
      "Already have GPC\n",
      "Already have GILD\n",
      "Already have GPN\n",
      "Already have GS\n",
      "Already have GWW\n",
      "Already have HAL\n",
      "Already have HBI\n",
      "Already have HOG\n",
      "Already have HRS\n",
      "Already have HIG\n",
      "Already have HAS\n",
      "Already have HCA\n",
      "Already have HCP\n",
      "Already have HP\n",
      "Already have HSIC\n",
      "Already have HSY\n",
      "Already have HES\n",
      "Already have HPE\n",
      "Already have HLT\n",
      "Already have HFC\n",
      "Already have HOLX\n",
      "Already have HD\n",
      "Already have HON\n",
      "Already have HRL\n",
      "Already have HST\n",
      "Already have HPQ\n",
      "Already have HUM\n",
      "Already have HBAN\n",
      "Already have HII\n",
      "Already have IDXX\n",
      "Already have INFO\n",
      "Already have ITW\n",
      "Already have ILMN\n",
      "Already have IR\n",
      "Already have INTC\n",
      "Already have ICE\n",
      "Already have IBM\n",
      "Already have INCY\n",
      "Already have IP\n",
      "Already have IPG\n",
      "Already have IFF\n",
      "Already have INTU\n",
      "Already have ISRG\n",
      "Already have IVZ\n",
      "Already have IPGP\n",
      "Already have IQV\n",
      "Already have IRM\n",
      "Already have JKHY\n",
      "Already have JEC\n",
      "Already have JBHT\n",
      "Already have JEF\n",
      "Already have SJM\n",
      "Already have JNJ\n",
      "Already have JCI\n",
      "Already have JPM\n",
      "Already have JNPR\n",
      "Already have KSU\n",
      "Already have K\n",
      "Already have KEY\n",
      "Already have KEYS\n",
      "Already have KMB\n",
      "Already have KIM\n",
      "Already have KMI\n",
      "Already have KLAC\n",
      "Already have KSS\n",
      "Already have KHC\n",
      "Already have KR\n",
      "Already have LB\n",
      "Already have LLL\n",
      "Already have LH\n",
      "Already have LRCX\n",
      "Already have LW\n",
      "Already have LEG\n",
      "Already have LEN\n",
      "Already have LLY\n",
      "Already have LNC\n",
      "Already have LIN\n",
      "Already have LKQ\n",
      "Already have LMT\n",
      "Already have L\n",
      "Already have LOW\n",
      "Already have LYB\n",
      "Already have MTB\n",
      "Already have MAC\n",
      "Already have M\n",
      "Already have MRO\n",
      "Already have MPC\n",
      "Already have MAR\n",
      "Already have MMC\n",
      "Already have MLM\n",
      "Already have MAS\n",
      "Already have MA\n",
      "Already have MAT\n",
      "Already have MKC\n",
      "Already have MXIM\n",
      "Already have MCD\n",
      "Already have MCK\n",
      "Already have MDT\n",
      "Already have MRK\n",
      "Already have MET\n",
      "Already have MTD\n",
      "Already have MGM\n",
      "Already have MCHP\n",
      "Already have MU\n",
      "Already have MSFT\n",
      "Already have MAA\n",
      "Already have MHK\n",
      "Already have TAP\n",
      "Already have MDLZ\n",
      "Already have MNST\n",
      "Already have MCO\n",
      "Already have MS\n",
      "Already have MOS\n",
      "Already have MSI\n",
      "Already have MSCI\n",
      "Already have MYL\n",
      "Already have NDAQ\n",
      "Already have NOV\n",
      "Already have NKTR\n",
      "Already have NTAP\n",
      "Already have NFLX\n",
      "Already have NWL\n",
      "Already have NEM\n",
      "Already have NWSA\n",
      "Already have NWS\n",
      "Already have NEE\n",
      "Already have NLSN\n",
      "Already have NKE\n",
      "Already have NI\n",
      "Already have NBL\n",
      "Already have JWN\n",
      "Already have NSC\n",
      "Already have NTRS\n",
      "Already have NOC\n",
      "Already have NCLH\n",
      "Already have NRG\n",
      "Already have NUE\n",
      "Already have NVDA\n",
      "Already have ORLY\n",
      "Already have OXY\n",
      "Already have OMC\n",
      "Already have OKE\n",
      "Already have ORCL\n",
      "Already have PCAR\n",
      "Already have PKG\n",
      "Already have PH\n",
      "Already have PAYX\n",
      "Already have PYPL\n",
      "Already have PNR\n",
      "Already have PBCT\n",
      "Already have PEP\n",
      "Already have PKI\n",
      "Already have PRGO\n",
      "Already have PFE\n",
      "Already have PM\n",
      "Already have PSX\n",
      "Already have PNW\n",
      "Already have PXD\n",
      "Already have PNC\n",
      "Already have PPG\n",
      "Already have PPL\n",
      "Already have PFG\n",
      "Already have PG\n",
      "Already have PGR\n",
      "Already have PLD\n",
      "Already have PRU\n",
      "Already have PEG\n",
      "Already have PSA\n",
      "Already have PHM\n",
      "Already have PVH\n",
      "Already have QRVO\n",
      "Already have PWR\n",
      "Already have QCOM\n",
      "Already have DGX\n",
      "Already have RL\n",
      "Already have RJF\n",
      "Already have RTN\n",
      "Already have O\n",
      "Already have RHT\n",
      "Already have REG\n",
      "Already have REGN\n",
      "Already have RF\n",
      "Already have RSG\n",
      "Already have RMD\n",
      "Already have RHI\n",
      "Already have ROK\n",
      "Already have ROL\n",
      "Already have ROP\n",
      "Already have ROST\n",
      "Already have RCL\n",
      "Already have CRM\n",
      "Already have SBAC\n",
      "Already have SLB\n",
      "Already have STX\n",
      "Already have SEE\n",
      "Already have SRE\n",
      "Already have SHW\n",
      "Already have SPG\n",
      "Already have SWKS\n",
      "Already have SLG\n",
      "Already have SNA\n",
      "Already have SO\n",
      "Already have LUV\n",
      "Already have SPGI\n",
      "Already have SWK\n",
      "Already have SBUX\n",
      "Already have STT\n",
      "Already have SYK\n",
      "Already have STI\n",
      "Already have SIVB\n",
      "Already have SYMC\n",
      "Already have SYF\n",
      "Already have SNPS\n",
      "Already have SYY\n",
      "Already have TROW\n",
      "Already have TTWO\n",
      "Already have TPR\n",
      "Already have TGT\n",
      "Already have TEL\n",
      "Already have FTI\n",
      "Already have TFX\n",
      "Already have TXN\n",
      "Already have TXT\n",
      "Already have TMO\n",
      "Already have TIF\n",
      "Already have TWTR\n",
      "Already have TJX\n",
      "Already have TMK\n",
      "Already have TSS\n",
      "Already have TSCO\n",
      "Already have TDG\n",
      "Already have TRV\n",
      "Already have TRIP\n",
      "Already have TSN\n",
      "Already have UDR\n",
      "Already have ULTA\n",
      "Already have USB\n",
      "Already have UAA\n",
      "Already have UA\n",
      "Already have UNP\n",
      "Already have UAL\n",
      "Already have UNH\n",
      "Already have UPS\n",
      "Already have URI\n",
      "Already have UTX\n",
      "Already have UHS\n",
      "Already have UNM\n",
      "Already have VFC\n",
      "Already have VLO\n",
      "Already have VAR\n",
      "Already have VTR\n",
      "Already have VRSN\n",
      "Already have VRSK\n",
      "Already have VZ\n",
      "Already have VRTX\n",
      "Already have VIAB\n",
      "Already have V\n",
      "Already have VNO\n",
      "Already have VMC\n",
      "Already have WAB\n",
      "Already have WMT\n",
      "Already have WBA\n",
      "Already have DIS\n",
      "Already have WM\n",
      "Already have WAT\n",
      "Already have WEC\n",
      "Already have WCG\n",
      "Already have WFC\n",
      "Already have WELL\n",
      "Already have WDC\n",
      "Already have WU\n",
      "Already have WRK\n",
      "Already have WY\n",
      "Already have WHR\n",
      "Already have WMB\n",
      "Already have WLTW\n",
      "Already have WYNN\n",
      "Already have XEL\n",
      "Already have XRX\n",
      "Already have XLNX\n",
      "Already have XYL\n",
      "Already have YUM\n",
      "Already have ZBH\n",
      "Already have ZION\n",
      "Already have ZTS\n"
     ]
    }
   ],
   "source": [
    "#Getting data from Yahoo\n",
    "def data_yahoo(reload_sp500=False):\n",
    "    if reload_sp500:\n",
    "        tickers = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2016, 1, 1)\n",
    "    end = dt.datetime.now()\n",
    "    for ticker in tickers:\n",
    "        # just in case your connection breaks, we'd like to save our progress!\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            df = web.DataReader(ticker, 'yahoo', start, end)\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "data_yahoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, the data from yahoo and the tickers are not very useful by themselves, so obvisouly we want to compile the data in order to get a dataframe with all tickers and their data. We open the pickle file again, and make an empty dataframe.\n",
    "\n",
    "We can then compile each ticker with their data. We drop all columns that are not *Adj Close*, and rename *Adj Close* to the ticker name since we do not have any other data than for Adjusted Close price. We choose to only include this, since the Adjusted Close price takes into account payment of dividends of companies, eventual stock splits, and Rights offerings.\n",
    "\n",
    "For easier comparison, we also index the data by dividing the first observation in each column by the rest of the column. \n",
    "\n",
    "We then use the empty data frame made before, and join all the data together into a single data frame. \n",
    "\n",
    "We also convert the data frame to a csv file for easy access to it. \n",
    "\n",
    "finally, we create a data frame from the CSV file just saved, and index the date. We call this new data frame *df_stocks*.\n",
    "\n",
    "It is important to note that we drop those companies that do not have stock data available for the entire period, those being \"BHGE\", \"DWDP\", \"TPR\", \"ARNC\", \"ZBH\", \"OKE\", \"EVRG\", \"COST\", \"EW\", \"BBT\", \"JNJ\", \"VMC\", \"LIN\", \"COTY\", \"DGX\", \"ZBH\", \"FTV\", \"LW\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have now compiled 0 stock files\n",
      "I have now compiled 100 stock files\n",
      "I have now compiled 200 stock files\n",
      "I have now compiled 300 stock files\n",
      "I have now compiled 400 stock files\n",
      "I have now compiled 500 stock files\n",
      "                   MMM        ABT       ABBV       ABMD        ACN       ATVI  \\\n",
      "Date                                                                            \n",
      "2016-01-04  135.163361  39.841354  50.214832  85.239998  95.316299  36.604977   \n",
      "2016-01-05  135.752548  39.832066  50.005642  85.000000  95.812393  36.137928   \n",
      "2016-01-06  133.018326  39.497967  50.014351  85.300003  95.625191  35.797367   \n",
      "2016-01-07  129.777802  38.551361  49.866177  81.919998  92.817101  35.291401   \n",
      "2016-01-08  129.335922  37.743946  48.506435  84.580002  91.918503  34.746506   \n",
      "\n",
      "                 ADBE   AMD         AAP       AES    ...            WLTW  \\\n",
      "Date                                                 ...                   \n",
      "2016-01-04  91.970001  2.77  151.373932  8.105658    ...      118.837708   \n",
      "2016-01-05  92.339996  2.75  150.339844  8.217405    ...      119.655312   \n",
      "2016-01-06  91.019997  2.51  146.362579  7.933745    ...      114.083321   \n",
      "2016-01-07  89.110001  2.28  147.983307  7.736048    ...      109.300514   \n",
      "2016-01-08  87.849998  2.14  144.731918  7.847791    ...      110.888451   \n",
      "\n",
      "                 WYNN        XEL        XRX       XLNX        XYL        YUM  \\\n",
      "Date                                                                           \n",
      "2016-01-04  64.482521  32.163685  25.023848  42.507366  34.595341  48.128719   \n",
      "2016-01-05  65.701477  32.488022  24.975262  43.138481  34.585754  48.008751   \n",
      "2016-01-06  62.297787  32.830379  24.659422  42.349586  34.154266  47.668831   \n",
      "2016-01-07  56.437443  32.956512  23.979164  40.678997  33.272129  46.042538   \n",
      "2016-01-08  54.140198  32.596134  23.298904  39.843700  32.955711  45.416023   \n",
      "\n",
      "            ZBH       ZION        ZTS  \n",
      "Date                                   \n",
      "2016-01-04  NaN  25.348028  46.097820  \n",
      "2016-01-05  NaN  25.072823  46.819458  \n",
      "2016-01-06  NaN  24.342087  46.829220  \n",
      "2016-01-07  NaN  23.611343  45.405415  \n",
      "2016-01-08  NaN  23.345621  44.742283  \n",
      "\n",
      "[5 rows x 505 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MMM</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>...</th>\n",
       "      <th>WMB</th>\n",
       "      <th>WLTW</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>135.163361</td>\n",
       "      <td>39.841354</td>\n",
       "      <td>50.214832</td>\n",
       "      <td>85.239998</td>\n",
       "      <td>95.316299</td>\n",
       "      <td>36.604977</td>\n",
       "      <td>91.970001</td>\n",
       "      <td>2.77</td>\n",
       "      <td>151.373932</td>\n",
       "      <td>...</td>\n",
       "      <td>21.791628</td>\n",
       "      <td>118.837708</td>\n",
       "      <td>64.482521</td>\n",
       "      <td>32.163685</td>\n",
       "      <td>25.023848</td>\n",
       "      <td>42.507366</td>\n",
       "      <td>34.595341</td>\n",
       "      <td>48.128719</td>\n",
       "      <td>25.348028</td>\n",
       "      <td>46.097820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>135.752548</td>\n",
       "      <td>39.832066</td>\n",
       "      <td>50.005642</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>95.812393</td>\n",
       "      <td>36.137928</td>\n",
       "      <td>92.339996</td>\n",
       "      <td>2.75</td>\n",
       "      <td>150.339844</td>\n",
       "      <td>...</td>\n",
       "      <td>21.866369</td>\n",
       "      <td>119.655312</td>\n",
       "      <td>65.701477</td>\n",
       "      <td>32.488022</td>\n",
       "      <td>24.975262</td>\n",
       "      <td>43.138481</td>\n",
       "      <td>34.585754</td>\n",
       "      <td>48.008751</td>\n",
       "      <td>25.072823</td>\n",
       "      <td>46.819458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>133.018326</td>\n",
       "      <td>39.497967</td>\n",
       "      <td>50.014351</td>\n",
       "      <td>85.300003</td>\n",
       "      <td>95.625191</td>\n",
       "      <td>35.797367</td>\n",
       "      <td>91.019997</td>\n",
       "      <td>2.51</td>\n",
       "      <td>146.362579</td>\n",
       "      <td>...</td>\n",
       "      <td>19.017845</td>\n",
       "      <td>114.083321</td>\n",
       "      <td>62.297787</td>\n",
       "      <td>32.830379</td>\n",
       "      <td>24.659422</td>\n",
       "      <td>42.349586</td>\n",
       "      <td>34.154266</td>\n",
       "      <td>47.668831</td>\n",
       "      <td>24.342087</td>\n",
       "      <td>46.829220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>129.777802</td>\n",
       "      <td>38.551361</td>\n",
       "      <td>49.866177</td>\n",
       "      <td>81.919998</td>\n",
       "      <td>92.817101</td>\n",
       "      <td>35.291401</td>\n",
       "      <td>89.110001</td>\n",
       "      <td>2.28</td>\n",
       "      <td>147.983307</td>\n",
       "      <td>...</td>\n",
       "      <td>17.116064</td>\n",
       "      <td>109.300514</td>\n",
       "      <td>56.437443</td>\n",
       "      <td>32.956512</td>\n",
       "      <td>23.979164</td>\n",
       "      <td>40.678997</td>\n",
       "      <td>33.272129</td>\n",
       "      <td>46.042538</td>\n",
       "      <td>23.611343</td>\n",
       "      <td>45.405415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>129.335922</td>\n",
       "      <td>37.743946</td>\n",
       "      <td>48.506435</td>\n",
       "      <td>84.580002</td>\n",
       "      <td>91.918503</td>\n",
       "      <td>34.746506</td>\n",
       "      <td>87.849998</td>\n",
       "      <td>2.14</td>\n",
       "      <td>144.731918</td>\n",
       "      <td>...</td>\n",
       "      <td>16.866919</td>\n",
       "      <td>110.888451</td>\n",
       "      <td>54.140198</td>\n",
       "      <td>32.596134</td>\n",
       "      <td>23.298904</td>\n",
       "      <td>39.843700</td>\n",
       "      <td>32.955711</td>\n",
       "      <td>45.416023</td>\n",
       "      <td>23.345621</td>\n",
       "      <td>44.742283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         MMM        ABT       ABBV       ABMD        ACN  \\\n",
       "0  2016-01-04  135.163361  39.841354  50.214832  85.239998  95.316299   \n",
       "1  2016-01-05  135.752548  39.832066  50.005642  85.000000  95.812393   \n",
       "2  2016-01-06  133.018326  39.497967  50.014351  85.300003  95.625191   \n",
       "3  2016-01-07  129.777802  38.551361  49.866177  81.919998  92.817101   \n",
       "4  2016-01-08  129.335922  37.743946  48.506435  84.580002  91.918503   \n",
       "\n",
       "        ATVI       ADBE   AMD         AAP    ...            WMB        WLTW  \\\n",
       "0  36.604977  91.970001  2.77  151.373932    ...      21.791628  118.837708   \n",
       "1  36.137928  92.339996  2.75  150.339844    ...      21.866369  119.655312   \n",
       "2  35.797367  91.019997  2.51  146.362579    ...      19.017845  114.083321   \n",
       "3  35.291401  89.110001  2.28  147.983307    ...      17.116064  109.300514   \n",
       "4  34.746506  87.849998  2.14  144.731918    ...      16.866919  110.888451   \n",
       "\n",
       "        WYNN        XEL        XRX       XLNX        XYL        YUM  \\\n",
       "0  64.482521  32.163685  25.023848  42.507366  34.595341  48.128719   \n",
       "1  65.701477  32.488022  24.975262  43.138481  34.585754  48.008751   \n",
       "2  62.297787  32.830379  24.659422  42.349586  34.154266  47.668831   \n",
       "3  56.437443  32.956512  23.979164  40.678997  33.272129  46.042538   \n",
       "4  54.140198  32.596134  23.298904  39.843700  32.955711  45.416023   \n",
       "\n",
       "        ZION        ZTS  \n",
       "0  25.348028  46.097820  \n",
       "1  25.072823  46.819458  \n",
       "2  24.342087  46.829220  \n",
       "3  23.611343  45.405415  \n",
       "4  23.345621  44.742283  \n",
       "\n",
       "[5 rows x 489 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compile_data():\n",
    "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    #Iterating though all DFs\n",
    "\n",
    "    for count, ticker in enumerate(tickers):\n",
    "        df = pd.read_csv(\"stock_dfs/{}.csv\".format(ticker))\n",
    "        df.set_index(\"Date\", inplace=True)\n",
    "        df.rename(columns = {\"Adj Close\": ticker}, inplace=True) #Adj Close takes the categories place in the column - Simple rename\n",
    "        df.drop([\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"],1, inplace=True)\n",
    "    \n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df, how=\"outer\")\n",
    "        \n",
    "        if count % 100 == 0: #Only print #100, #200, #300, etc. - It will let you know how \n",
    "            print(\"I have now compiled\", count, \"stock files\")\n",
    "    print(main_df.head())\n",
    "    main_df.to_csv(\"sp500_joined_adj_closes.csv\")\n",
    "\n",
    "compile_data()\n",
    "\n",
    "data_df = pd.read_csv(\"sp500_joined_adj_closes.csv\")\n",
    "data_df = data_df.drop([\"BHGE\", \"DWDP\", \"TPR\", \"ARNC\", \"ZBH\", \"OKE\", \"EVRG\", \"COST\", \"EW\", \"BBT\", \"JNJ\", \"VMC\", \"LIN\", \"COTY\", \"DGX\", \"ZBH\", \"FTV\", \"LW\"], axis=1)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the data collected, we can now look at how the price of each stock has changed through time. The code below will make an interactive widget that shows the observed adjusted close price for each date available in each file.\n",
    "\n",
    "The reader can choose between two individual stocks and compare the close price for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c132d3e7a6f445d38c13311df127c1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Company 1:', index=51, options=('A', 'AAL', 'AAP', 'AAPL', 'ABBV',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_w(dataframe, ticker, benchmark)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_w(dataframe,ticker,benchmark):\n",
    "    \n",
    "    # a. Printing highest observed values and corresponding date\n",
    "    max1 = data_df.loc[:, ticker].max()\n",
    "    max2 = data_df.loc[:, benchmark].max()\n",
    "    max1_date = next(iter(data_df.loc[data_df[ticker] == max1, 'Date']), 'no match') # Finding corresponding date \n",
    "    max2_date = data_df[data_df[benchmark] == max2]['Date'].values[0] # Finding corresponding date alternative version\n",
    "    print(\"The highest adjusted close price observed at: \\n\", ticker, \":\", max1.round(2), \"USD on the date \", max1_date, \n",
    "          \"\\n\", benchmark, \":\", max2.round(2), \"USD on the date\", max2_date)\n",
    "    \n",
    "    # b. Setting up plot based on dropdown input\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    mpl_figure = dataframe.loc[:, ['Date',ticker,benchmark]]\n",
    "    mpl_figure.plot(x='Date', y=[ticker,benchmark], style=['-b','-k'], ax=ax, fontsize=11, legend='true', linestyle = '-')\n",
    "    plt.ylabel(\"USD\",labelpad=5)\n",
    "    plt.locator_params(axis='x', nbins=20)\n",
    "    title = \"Adjusted close prices for \" + ticker + \" and \" + benchmark\n",
    "    plt.title(title)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    #date = data_df.iloc[::55,0]\n",
    "    #datetime = data_df['Date'].dt.strftime('%m/%Y')\n",
    "    xlabels = data_df.iloc[::52,0]\n",
    "    #ax.set_xticks(xlabels)\n",
    "    ax.set_xticklabels(xlabels, minor = False)\n",
    "    #ax.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    \n",
    "# c. Creating the widget for the plot\n",
    "widgets.interact(plot_w,\n",
    "    dataframe = widgets.fixed(data_df),\n",
    "    ticker = widgets.Dropdown(\n",
    "            options=data_df[data_df.columns.difference(['Date'])],\n",
    "            value='ATVI',\n",
    "            description='Company 1:',\n",
    "            disabled=False,\n",
    "        ),\n",
    "    benchmark = widgets.Dropdown(\n",
    "            options=data_df[data_df.columns.difference(['Date'])],\n",
    "            value='AAPL',\n",
    "            description='Company 2:',\n",
    "            disabled=False,\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the graph above, taking our starting point with Activision blizzard and Apple, we see that in most recent times, the two stocks have followed a relatively positive trend, where they both then dropped around early february of this year. The Apple stock has since then managed to bounce back, whereas the Activision Blizzard stock has not. \n",
    "\n",
    "A problem does occor, however, when comparing two stocks that have very different price levels. We can fix this problem by indexing the stock data so that each stock is comparable with eachother no matter the price level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sp500 index data\n",
    "data_df_indexed = data_df.set_index(\"Date\", inplace=True) #setting the index so that we don't get a column with dates, that we cannot divide with.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_indexed = data_df/data_df.iloc[0]*100 #We do the calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMM</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AES</th>\n",
       "      <th>...</th>\n",
       "      <th>WMB</th>\n",
       "      <th>WLTW</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>100.435908</td>\n",
       "      <td>99.976686</td>\n",
       "      <td>99.583409</td>\n",
       "      <td>99.718445</td>\n",
       "      <td>100.520471</td>\n",
       "      <td>98.724084</td>\n",
       "      <td>100.402300</td>\n",
       "      <td>99.277979</td>\n",
       "      <td>99.316865</td>\n",
       "      <td>101.378639</td>\n",
       "      <td>...</td>\n",
       "      <td>100.342982</td>\n",
       "      <td>100.688001</td>\n",
       "      <td>101.890367</td>\n",
       "      <td>101.008395</td>\n",
       "      <td>99.805842</td>\n",
       "      <td>101.484719</td>\n",
       "      <td>99.972290</td>\n",
       "      <td>99.750734</td>\n",
       "      <td>98.914292</td>\n",
       "      <td>101.565449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>98.413006</td>\n",
       "      <td>99.138113</td>\n",
       "      <td>99.600753</td>\n",
       "      <td>100.070396</td>\n",
       "      <td>100.324070</td>\n",
       "      <td>97.793717</td>\n",
       "      <td>98.967050</td>\n",
       "      <td>90.613719</td>\n",
       "      <td>96.689422</td>\n",
       "      <td>97.879109</td>\n",
       "      <td>...</td>\n",
       "      <td>87.271338</td>\n",
       "      <td>95.999261</td>\n",
       "      <td>96.611897</td>\n",
       "      <td>102.072818</td>\n",
       "      <td>98.543687</td>\n",
       "      <td>99.628818</td>\n",
       "      <td>98.725047</td>\n",
       "      <td>99.044461</td>\n",
       "      <td>96.031481</td>\n",
       "      <td>101.586625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>96.015519</td>\n",
       "      <td>96.762175</td>\n",
       "      <td>99.305672</td>\n",
       "      <td>96.105115</td>\n",
       "      <td>97.377994</td>\n",
       "      <td>96.411483</td>\n",
       "      <td>96.890290</td>\n",
       "      <td>82.310469</td>\n",
       "      <td>97.760100</td>\n",
       "      <td>95.440101</td>\n",
       "      <td>...</td>\n",
       "      <td>78.544220</td>\n",
       "      <td>91.974607</td>\n",
       "      <td>87.523629</td>\n",
       "      <td>102.464978</td>\n",
       "      <td>95.825248</td>\n",
       "      <td>95.698700</td>\n",
       "      <td>96.175174</td>\n",
       "      <td>95.665412</td>\n",
       "      <td>93.148639</td>\n",
       "      <td>98.497964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>95.688596</td>\n",
       "      <td>94.735600</td>\n",
       "      <td>96.597824</td>\n",
       "      <td>99.225720</td>\n",
       "      <td>96.435241</td>\n",
       "      <td>94.922901</td>\n",
       "      <td>95.520275</td>\n",
       "      <td>77.256322</td>\n",
       "      <td>95.612181</td>\n",
       "      <td>96.818686</td>\n",
       "      <td>...</td>\n",
       "      <td>77.400911</td>\n",
       "      <td>93.310829</td>\n",
       "      <td>83.961044</td>\n",
       "      <td>101.344527</td>\n",
       "      <td>93.106803</td>\n",
       "      <td>93.733637</td>\n",
       "      <td>95.260549</td>\n",
       "      <td>94.363665</td>\n",
       "      <td>92.100344</td>\n",
       "      <td>97.059433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 488 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MMM         ABT        ABBV        ABMD         ACN  \\\n",
       "Date                                                                     \n",
       "2016-01-04  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "2016-01-05  100.435908   99.976686   99.583409   99.718445  100.520471   \n",
       "2016-01-06   98.413006   99.138113   99.600753  100.070396  100.324070   \n",
       "2016-01-07   96.015519   96.762175   99.305672   96.105115   97.377994   \n",
       "2016-01-08   95.688596   94.735600   96.597824   99.225720   96.435241   \n",
       "\n",
       "                  ATVI        ADBE         AMD         AAP         AES  \\\n",
       "Date                                                                     \n",
       "2016-01-04  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "2016-01-05   98.724084  100.402300   99.277979   99.316865  101.378639   \n",
       "2016-01-06   97.793717   98.967050   90.613719   96.689422   97.879109   \n",
       "2016-01-07   96.411483   96.890290   82.310469   97.760100   95.440101   \n",
       "2016-01-08   94.922901   95.520275   77.256322   95.612181   96.818686   \n",
       "\n",
       "               ...             WMB        WLTW        WYNN         XEL  \\\n",
       "Date           ...                                                       \n",
       "2016-01-04     ...      100.000000  100.000000  100.000000  100.000000   \n",
       "2016-01-05     ...      100.342982  100.688001  101.890367  101.008395   \n",
       "2016-01-06     ...       87.271338   95.999261   96.611897  102.072818   \n",
       "2016-01-07     ...       78.544220   91.974607   87.523629  102.464978   \n",
       "2016-01-08     ...       77.400911   93.310829   83.961044  101.344527   \n",
       "\n",
       "                   XRX        XLNX         XYL         YUM        ZION  \\\n",
       "Date                                                                     \n",
       "2016-01-04  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "2016-01-05   99.805842  101.484719   99.972290   99.750734   98.914292   \n",
       "2016-01-06   98.543687   99.628818   98.725047   99.044461   96.031481   \n",
       "2016-01-07   95.825248   95.698700   96.175174   95.665412   93.148639   \n",
       "2016-01-08   93.106803   93.733637   95.260549   94.363665   92.100344   \n",
       "\n",
       "                   ZTS  \n",
       "Date                    \n",
       "2016-01-04  100.000000  \n",
       "2016-01-05  101.565449  \n",
       "2016-01-06  101.586625  \n",
       "2016-01-07   98.497964  \n",
       "2016-01-08   97.059433  \n",
       "\n",
       "[5 rows x 488 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_indexed.head() #We print just to make sure that this has been done right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_indexed= data_df_indexed.reset_index() #We then reset the index so that we can use the column \"Dates\" on the x-axis in the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d50b00aca5414fb8efc13d70a661c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Company 1:', index=5, options=('MMM', 'ABT', 'ABBV', 'ABMD', 'ACN'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_index(dataframe_index, ticker, benchmark)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. Printing highest observed values\n",
    "def plot_index(dataframe_index,ticker,benchmark):\n",
    "#print(data_df.loc[:, I]) # 850 rows \n",
    "    max1 = data_df_indexed.loc[:, ticker].max()\n",
    "    max2 = data_df_indexed.loc[:, benchmark].max()\n",
    "    print(\"The highest stock price observed at: \\n\", ticker, \":\", max1.round(2), \" USD on the date \", \"2\", \n",
    "    \"\\n\", benchmark, \":\", max2.round(2), \" USD on the date\", \"test\")\n",
    "\n",
    "# b. Setting up plot based on dropdown input\n",
    "    I = data_df_indexed.columns == ticker\n",
    "    plt = dataframe_index.loc[:, ['Date',ticker,benchmark]].plot(x='Date', y=[ticker,benchmark], style=['-b','-k'], figsize=(8, 5), fontsize=11, legend='true')\n",
    "\n",
    "# c. Creating the widget for the plot\n",
    "widgets.interact(plot_index, \n",
    "                 dataframe_index = widgets.fixed(data_df_indexed), \n",
    "                 ticker = widgets.Dropdown(\n",
    "                          options=data_df.columns, value='ATVI', \n",
    "                          description='Company 1:', disabled=False,),\n",
    "\n",
    "                benchmark = widgets.Dropdown(options=data_df_indexed.columns, value='AAPL', \n",
    "                                 description='Company 2:', disabled=False,)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see now, using the same two stocks as reference, it is now much easier to compare stock development. The conclusions from before when we only looked at raw adjusted close prices are the same now. The trend for each of the two are around the same until early february where Apple then manages to turn around into a positive trend and ATVI remains at a new level. Although the story is still the same for the two, it is now a lot easier to see now that the data has been indexed. \n",
    "\n",
    "Next up we wish to analyse the stock returns, which we will do by looking at the percentage change for each day of each individual stock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pct. change on the closing prices. \n",
    "data_df_pct_change = data_df.apply(lambda x: (x - x.shift(1))/x.shift(1)*100) #we take the observed price for day 1, substract the value from the day before and then divide by the day before.\n",
    "data_df_pct_change = data_df_pct_change.fillna(value=0) #Since we cannot subtract a value from the first observed day, we get an entire row of NaN values. We fill these with zeros. \n",
    "data_df_pct_change.head() #We print to make sure the dataframe looks correct. \n",
    "\n",
    "data_df_pct_change = data_df_pct_change.reset_index() #Again we reset the index in order to use the \"Date\" on the x-axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0951cc58aab416680c106f30eebaaf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Company 1:', index=5, options=('MMM', 'ABT', 'ABBV', 'ABMD', 'ACN'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_pct_change(dataframe_pct_change, ticker, benchmark)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. Printing highest observed values\n",
    "def plot_pct_change(dataframe_pct_change,ticker,benchmark): \n",
    "#print(data_df.loc[:, I]) # 850 rows \n",
    "    max1 = data_df_pct_change.loc[:, ticker].max() #We want to report the highest percentage change and the date it occured for company 1.\n",
    "    max2 = data_df_pct_change.loc[:, benchmark].max() #We want to report the highest percentage change and the date it occured for company 2.\n",
    "    print(\"The highest percentage change: \\n\", ticker, \":\", max1.round(2), \" pct. on the date \", \"2\", \n",
    "    \"\\n\", benchmark, \":\", max2.round(2), \" pct. on the date\", \"test\") \n",
    "# b. Setting up plot based on dropdown input\n",
    "    I = data_df_pct_change.columns == ticker #We define I as all the tickers\n",
    "    plt = dataframe_pct_change.loc[:, ['Date',ticker,benchmark]].plot(x='Date', y=[ticker,benchmark], style=['-b','-g'], figsize=(8, 5), fontsize=11, legend='true') #We then define the plot itself\n",
    "\n",
    "# c. Creating the widget for the plot\n",
    "widgets.interact(plot_pct_change, \n",
    "                 dataframe_pct_change = widgets.fixed(data_df_pct_change), \n",
    "                 ticker = widgets.Dropdown(\n",
    "                          options=data_df.columns, value='ATVI', \n",
    "                          description='Company 1:', disabled=False,),\n",
    "\n",
    "                benchmark = widgets.Dropdown(options=data_df_pct_change.columns, value='AAPL', \n",
    "                                 description='Company 2:', disabled=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an instrument that will tell us if a stock has a tendency of yielding very positive and negative returns, or if the returns are somewhat minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see what stocks a single stock is most correlated with, least correlated with, and most negatively correlated with. This will in theory help the individual put together a portfolio of additional stocks if that portfolio only consists of a few stocks already. Since we only have data for a few years, we have decided to base the correlation calculates on the percentage change for each stock, as most literature suggests to base correlation between stocks on their returns on the short run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMM</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AES</th>\n",
       "      <th>...</th>\n",
       "      <th>WMB</th>\n",
       "      <th>WLTW</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434111</td>\n",
       "      <td>0.336578</td>\n",
       "      <td>0.264108</td>\n",
       "      <td>0.498707</td>\n",
       "      <td>0.280339</td>\n",
       "      <td>0.417762</td>\n",
       "      <td>0.206384</td>\n",
       "      <td>0.166423</td>\n",
       "      <td>0.277283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223970</td>\n",
       "      <td>0.405373</td>\n",
       "      <td>0.251276</td>\n",
       "      <td>0.132721</td>\n",
       "      <td>0.362730</td>\n",
       "      <td>0.488232</td>\n",
       "      <td>0.596775</td>\n",
       "      <td>0.405610</td>\n",
       "      <td>0.340739</td>\n",
       "      <td>0.443617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <td>0.434111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.457360</td>\n",
       "      <td>0.450732</td>\n",
       "      <td>0.484020</td>\n",
       "      <td>0.342146</td>\n",
       "      <td>0.493453</td>\n",
       "      <td>0.290314</td>\n",
       "      <td>0.214780</td>\n",
       "      <td>0.262426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202408</td>\n",
       "      <td>0.374291</td>\n",
       "      <td>0.226561</td>\n",
       "      <td>0.102206</td>\n",
       "      <td>0.325227</td>\n",
       "      <td>0.371582</td>\n",
       "      <td>0.439535</td>\n",
       "      <td>0.393401</td>\n",
       "      <td>0.343151</td>\n",
       "      <td>0.530334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>0.336578</td>\n",
       "      <td>0.457360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.306029</td>\n",
       "      <td>0.334571</td>\n",
       "      <td>0.214254</td>\n",
       "      <td>0.328809</td>\n",
       "      <td>0.165315</td>\n",
       "      <td>0.151816</td>\n",
       "      <td>0.144665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208775</td>\n",
       "      <td>0.286081</td>\n",
       "      <td>0.172011</td>\n",
       "      <td>0.059425</td>\n",
       "      <td>0.215166</td>\n",
       "      <td>0.229910</td>\n",
       "      <td>0.307586</td>\n",
       "      <td>0.219717</td>\n",
       "      <td>0.269321</td>\n",
       "      <td>0.440411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABMD</th>\n",
       "      <td>0.264108</td>\n",
       "      <td>0.450732</td>\n",
       "      <td>0.306029</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.407676</td>\n",
       "      <td>0.334404</td>\n",
       "      <td>0.486673</td>\n",
       "      <td>0.269574</td>\n",
       "      <td>0.148915</td>\n",
       "      <td>0.160628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256828</td>\n",
       "      <td>0.276830</td>\n",
       "      <td>0.278435</td>\n",
       "      <td>-0.014634</td>\n",
       "      <td>0.223936</td>\n",
       "      <td>0.281301</td>\n",
       "      <td>0.338265</td>\n",
       "      <td>0.325665</td>\n",
       "      <td>0.236613</td>\n",
       "      <td>0.412202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <td>0.498707</td>\n",
       "      <td>0.484020</td>\n",
       "      <td>0.334571</td>\n",
       "      <td>0.407676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393214</td>\n",
       "      <td>0.550518</td>\n",
       "      <td>0.254905</td>\n",
       "      <td>0.218867</td>\n",
       "      <td>0.298163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259396</td>\n",
       "      <td>0.454752</td>\n",
       "      <td>0.267392</td>\n",
       "      <td>0.128098</td>\n",
       "      <td>0.361623</td>\n",
       "      <td>0.414756</td>\n",
       "      <td>0.471732</td>\n",
       "      <td>0.456129</td>\n",
       "      <td>0.385275</td>\n",
       "      <td>0.485583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 488 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           MMM       ABT      ABBV      ABMD       ACN      ATVI      ADBE  \\\n",
       "MMM   1.000000  0.434111  0.336578  0.264108  0.498707  0.280339  0.417762   \n",
       "ABT   0.434111  1.000000  0.457360  0.450732  0.484020  0.342146  0.493453   \n",
       "ABBV  0.336578  0.457360  1.000000  0.306029  0.334571  0.214254  0.328809   \n",
       "ABMD  0.264108  0.450732  0.306029  1.000000  0.407676  0.334404  0.486673   \n",
       "ACN   0.498707  0.484020  0.334571  0.407676  1.000000  0.393214  0.550518   \n",
       "\n",
       "           AMD       AAP       AES    ...          WMB      WLTW      WYNN  \\\n",
       "MMM   0.206384  0.166423  0.277283    ...     0.223970  0.405373  0.251276   \n",
       "ABT   0.290314  0.214780  0.262426    ...     0.202408  0.374291  0.226561   \n",
       "ABBV  0.165315  0.151816  0.144665    ...     0.208775  0.286081  0.172011   \n",
       "ABMD  0.269574  0.148915  0.160628    ...     0.256828  0.276830  0.278435   \n",
       "ACN   0.254905  0.218867  0.298163    ...     0.259396  0.454752  0.267392   \n",
       "\n",
       "           XEL       XRX      XLNX       XYL       YUM      ZION       ZTS  \n",
       "MMM   0.132721  0.362730  0.488232  0.596775  0.405610  0.340739  0.443617  \n",
       "ABT   0.102206  0.325227  0.371582  0.439535  0.393401  0.343151  0.530334  \n",
       "ABBV  0.059425  0.215166  0.229910  0.307586  0.219717  0.269321  0.440411  \n",
       "ABMD -0.014634  0.223936  0.281301  0.338265  0.325665  0.236613  0.412202  \n",
       "ACN   0.128098  0.361623  0.414756  0.471732  0.456129  0.385275  0.485583  \n",
       "\n",
       "[5 rows x 488 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_corr = data_df.pct_change().corr()\n",
    "df = data_df_corr\n",
    "data = df\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee227344bd0e43419f360f837a069c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Company 1:', options=('MMM', 'ABT', 'ABBV', 'ABMD', 'ACN', 'ATVI',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize_data(dataframe_corr, ticker)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_data(dataframe_corr, ticker):                \n",
    "    #df.set_index('Date', inplace=True) \n",
    "    #df_corr = df.corr()\n",
    "    #df_corr = df.corr()\n",
    "    #I = data.columns\n",
    "    #print(df_corr.head)\n",
    "    \n",
    "    \n",
    "    figure = dataframe_corr.loc[:, ticker]\n",
    "    #print(figure.head())\n",
    "    #corr_matrix = figure.drop(figure.loc(ticker), axis=0)\n",
    "    mostpos_corr = dataframe_corr.loc[:, ticker].nlargest(n=6)\n",
    "    no_corr = dataframe_corr.loc[:, ticker].abs().min()\n",
    "    mostneg_corr = dataframe_corr.loc[:, ticker].nsmallest(n=5)\n",
    "    least_corr = dataframe_corr[dataframe_corr[ticker] == no_corr].index.values[0]\n",
    "\n",
    "    \n",
    "    print(\"The 5 most positively correlated companies with\", ticker, \"are: \\n\", mostpos_corr[1:], \"\\n\")\n",
    "    \n",
    "    print(\"The company\", ticker, \"is most uncorrelated with is\", least_corr, \"with a correlation of:\", no_corr.round(6), \"\\n\")\n",
    "\n",
    "    print(\"The 5 most negatively correlated companies with\", ticker, \"are: \\n\", mostneg_corr[:])\n",
    "\n",
    "\n",
    "# c. Creating the widget for the plot\n",
    "widgets.interact(visualize_data, \n",
    "                 dataframe_corr = widgets.fixed(data), \n",
    "                 ticker = widgets.Dropdown(\n",
    "                          options=data_df_corr.columns, value='MMM', \n",
    "                          description='Company 1:', disabled=False,)\n",
    "                 \n",
    "\n",
    "                )\n",
    "     \n",
    "#least_corr = dataframe_corr[dataframe_corr[ticker] == no_corr][ticker]\n",
    "#print(least_corr) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then want to graph a single stock and compare it to the growth of the index as a whole. We start by making a copy of the data we have, using only *\"ATVI\"* and the *\"S&P500\"* data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the graph above, we see the growth in the Activision Blizzard stock compared to the S&P500 index. We see that the Activision Blizzard stock has experience a wild growth since its start in 2000. The spike around 2008 is due to the merge between Activision Entertainment and Blizzard Entertainment. The rise since ca. 2013 can be due to the rise in popularity and availability to video games. The eventual drastic fall in the end of the series comes after Blizzcon 2018 where a very unpopular annoucement was made, resulting in t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
